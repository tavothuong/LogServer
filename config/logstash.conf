input {
  udp {
    host => "0.0.0.0"
    port => 10514
    codec => "json"
  }
}

# This is an empty filter block.  You can later add other filters here to further process
# your log lines

filter { 
	grok {
		match => {
			"message" => [
                    "%{TIMESTAMP_ISO8601:timestamp} %{GREEDYDATA:server}:%{GREEDYDATA:host} %{LOGLEVEL:loglevel} %{GREEDYDATA:datalog}",
                    "%{GREEDYDATA:host} %{GREEDYDATA:server} %{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel} %{GREEDYDATA:thread}@%{GREEDYDATA:class}:%{GREEDYDATA:line} %{GREEDYDATA:message}"
                	]
		}
		overwrite => [ "host", "message" ] 
	}
	date {
      	match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss"]  
      	target => "@timestamp"   
        locale => "en" 
        timezone => "Asia/Ho_Chi_Minh" 
      	remove_field => ["timestamp"]
  }
  mutate {
   lowercase => [ "server" ]
  }
  if [loglevel]== "INFO" 
  {
    kv {
       source => "datalog"
       field_split => "&"
       value_split => "="
    }
    mutate {
      remove_field => [ "message", "datalog"]
    }
  }
   mutate {
    remove_field => ["headers","@version"]
  }
  if "_grokparsefailure" in [tags] {
   	drop { }
  }
}

# This output block will send all events of type "rsyslog" to Elasticsearch at the configured
# host and port into daily indices of the pattern, "rsyslog-YYYY.MM.DD"

output {
  	elasticsearch {
      hosts => ["0.0.0.0:9200"]
      index => "%{server}-%{+YYYY.MM.dd}"
    }
}